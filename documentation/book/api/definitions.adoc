
[[_definitions]]
== Definitions

[[_assignedtopicpartitions]]
=== AssignedTopicPartitions
__Type__ : < string, < integer (int32) > array > map


[[_bridgeinfo]]
=== BridgeInfo
Information about Kafka Bridge instance.


[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**bridge_version** +
__optional__|string
|===


[[_consumer]]
=== Consumer

[options="header", cols=".^3a,.^11a,.^4a"]
|===
|Name|Description|Schema
|**auto.offset.reset** +
__optional__|Resets the offset position for the consumer.
If set to `earliest`, messages are read from the first offset.
If set to `latest`, messages are read from the latest offset.|string
|**consumer.request.timeout.ms** +
__optional__|Sets the maximum amount of time, in milliseconds, for the consumer to wait for messages for a request. If the timeout period is reached without a response, an error is returned.|integer
|**enable.auto.commit** +
__optional__|If set to `true`, message offsets are committed automatically for the consumer. If set to `false`, message offsets must be committed manually.|boolean
|**fetch.min.bytes** +
__optional__|Sets the minimum ammount of data, in bytes, for the consumer to receive. The broker waits until the data to send exceeds this amount.|integer
|**format** +
__optional__|The allowable message format for the consumer, which can be `binary` (default) or `json`. The messages are converted into a JSON format.|string
|**name** +
__optional__|The unique name for the consumer instance. The name is unique within the scope of the consumer group. The name is used in URLs.|string
|===


[[_consumerrecord]]
=== ConsumerRecord

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**headers** +
__optional__|<<_kafkaheaderlist,KafkaHeaderList>>
|**key** +
__optional__|string
|**offset** +
__optional__|integer (int64)
|**partition** +
__optional__|integer (int32)
|**topic** +
__optional__|string
|**value** +
__optional__|string
|===


[[_consumerrecordlist]]
=== ConsumerRecordList
__Type__ : < <<_consumerrecord,ConsumerRecord>> > array


[[_createdconsumer]]
=== CreatedConsumer

[options="header", cols=".^3a,.^11a,.^4a"]
|===
|Name|Description|Schema
|**base_uri** +
__optional__|Base URI used to construct URIs for subsequent requests against this consumer instance.|string
|**instance_id** +
__optional__|Unique ID for the consumer instance in the group.|string
|===


[[_error]]
=== Error

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**error_code** +
__optional__|integer (int32)
|**message** +
__optional__|string
|===


[[_kafkaheader]]
=== KafkaHeader

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**key** +
__required__|string
|**value** +
__required__|string
|===


[[_kafkaheaderlist]]
=== KafkaHeaderList
__Type__ : < <<_kafkaheader,KafkaHeader>> > array


[[_offsetcommitseek]]
=== OffsetCommitSeek

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**offset** +
__required__|integer (int64)
|**partition** +
__required__|integer (int32)
|**topic** +
__required__|string
|===


[[_offsetcommitseeklist]]
=== OffsetCommitSeekList

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**offsets** +
__optional__|< <<_offsetcommitseek,OffsetCommitSeek>> > array
|===


[[_offsetrecordsent]]
=== OffsetRecordSent

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**offset** +
__optional__|integer (int64)
|**partition** +
__optional__|integer (int32)
|===


[[_offsetrecordsentlist]]
=== OffsetRecordSentList

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**offsets** +
__optional__|< <<_offsetrecordsent,OffsetRecordSent>> > array
|===


[[_partition]]
=== Partition

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**partition** +
__optional__|integer (int32)
|**topic** +
__optional__|string
|===


[[_partitionmetadata]]
=== PartitionMetadata

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**leader** +
__optional__|integer (int32)
|**partition** +
__optional__|integer (int32)
|**replicas** +
__optional__|< <<_replica,Replica>> > array
|===


[[_partitions]]
=== Partitions

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**partitions** +
__optional__|< <<_partition,Partition>> > array
|===


[[_producerrecord]]
=== ProducerRecord

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**headers** +
__optional__|<<_kafkaheaderlist,KafkaHeaderList>>
|**partition** +
__optional__|integer (int32)
|===


[[_producerrecordlist]]
=== ProducerRecordList

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**records** +
__optional__|< <<_producerrecord,ProducerRecord>> > array
|===


[[_producerrecordtopartition]]
=== ProducerRecordToPartition
__Type__ : object


[[_producerrecordtopartitionlist]]
=== ProducerRecordToPartitionList

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**records** +
__optional__|< <<_producerrecordtopartition,ProducerRecordToPartition>> > array
|===


[[_replica]]
=== Replica

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**broker** +
__optional__|integer (int32)
|**in_sync** +
__optional__|boolean
|**leader** +
__optional__|boolean
|===


[[_subscribedtopiclist]]
=== SubscribedTopicList

[options="header", cols=".^3a,.^4a"]
|===
|Name|Schema
|**partitions** +
__optional__|< <<_assignedtopicpartitions,AssignedTopicPartitions>> > array
|**topics** +
__optional__|<<_topics,Topics>>
|===


[[_topicmetadata]]
=== TopicMetadata

[options="header", cols=".^3a,.^11a,.^4a"]
|===
|Name|Description|Schema
|**configs** +
__optional__|Per-topic configuration overrides|< string, string > map
|**name** +
__optional__|Name of the topic|string
|**partitions** +
__optional__||< <<_partitionmetadata,PartitionMetadata>> > array
|===


[[_topics]]
=== Topics

[options="header", cols=".^3a,.^11a,.^4a"]
|===
|Name|Description|Schema
|**topic_pattern** +
__optional__|A regex topic pattern for matching multiple topics|string
|**topics** +
__optional__||< string > array
|===



